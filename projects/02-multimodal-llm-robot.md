# ğŸ¤ ë©€í‹°ëª¨ë‹¬ LLM í˜‘ë™ë¡œë´‡ ì§€ëŠ¥ì œì–´ ì‹œìŠ¤í…œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**ì‘ì—… ê¸°ê°„**: 2025.12  
**í”„ë¡œì íŠ¸ ë¶„ë¥˜**: ROS2 í”„ë¡œì íŠ¸ (ROKEY ë¶€íŠ¸ìº í”„)  
**ì°¸ì—¬ ì¸ì›**: 9ëª…  
**ê¸°ì—¬ë„**: ì˜ìƒ ì¸ì‹ ë° ëª¨ì…˜ ì œì–´ (35%)

### í”„ë¡œì íŠ¸ ì„¤ëª…

í˜‘ë™ë¡œë´‡ì´ ìì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì§€ëŠ¥í˜• ì œì–´ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Webcamìœ¼ë¡œ ì‹¤ì‹œê°„ ì˜ìƒì„ ì…ë ¥ë°›ì•„ **YOLOWorld**ì™€ **Hand Detector**ë¥¼ í™œìš©í•˜ì—¬ ë¬¼ì²´ì™€ ì‚¬ëŒì˜ ì† ë™ì‘ì„ ì¸ì‹í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜‘ë™ë¡œë´‡ì´ ìë™ìœ¼ë¡œ ì ì ˆí•œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**í•µì‹¬**: ì˜ìƒ ì¸ì‹ + ë¡œë´‡ ì œì–´ë¥¼ í†µí•œ **ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ì‘ìš© ì‹œìŠ¤í…œ**

---

## ğŸ¯ ë‹´ë‹¹ ì—­í•  (ì”¨í”„ë¡œ ì§ë¬´ ì—°ê´€)

### âœ… Webcam ê¸°ë°˜ ì‹¤ì‹œê°„ ì˜ìƒ ì…ë ¥ ë° ì²˜ë¦¬ (Python + OpenCV)

**ë‹´ë‹¹ ë‚´ìš©**
- Webcamì—ì„œ ì‹¤ì‹œê°„ í”„ë ˆì„ ìº¡ì²˜
- í”„ë ˆì„ ì „ì²˜ë¦¬ (í•´ìƒë„ ì¡°ì •, ì •ê·œí™”)
- ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ ìµœì†Œí™”

**êµ¬í˜„ ì½”ë“œ**
```python
import cv2
import numpy as np
from collections import deque
import threading

class WebcamCapture:
    def __init__(self, camera_id=0, fps=30):
        self.cap = cv2.VideoCapture(camera_id)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, fps)
        
        self.frame_buffer = deque(maxlen=5)
        self.is_running = True
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í”„ë ˆì„ ìº¡ì²˜ (ë©”ì¸ ë£¨í”„ ë¸”ë¡œí‚¹ ë°©ì§€)
        self.capture_thread = threading.Thread(target=self._capture_loop)
        self.capture_thread.daemon = True
        self.capture_thread.start()
    
    def _capture_loop(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”„ë ˆì„ ê³„ì† ìº¡ì²˜"""
        while self.is_running:
            ret, frame = self.cap.read()
            if ret:
                # í”„ë ˆì„ ì „ì²˜ë¦¬
                frame_preprocessed = self._preprocess(frame)
                self.frame_buffer.append(frame_preprocessed)
    
    def _preprocess(self, frame):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ì •ê·œí™”
        frame = frame.astype(np.float32) / 255.0
        
        # ë…¸ì´ì¦ˆ ì œê±°
        frame = cv2.GaussianBlur(frame, (5, 5), 0)
        
        return frame
    
    def get_latest_frame(self):
        """ìµœì‹  í”„ë ˆì„ ë°˜í™˜"""
        if self.frame_buffer:
            return self.frame_buffer[-1]
        return None
    
    def release(self):
        self.is_running = False
        self.cap.release()
```

**ì„±ê³¼**
- í”„ë ˆì„ë ˆì´íŠ¸: 30 FPS ì•ˆì •ì  ìœ ì§€
- ìº¡ì²˜ ë ˆì´í„´ì‹œ: < 50ms
- ë©”ëª¨ë¦¬ ì‚¬ìš©: ìµœì†Œí™” (ë²„í¼ í¬ê¸° 5)

---

### âœ… YOLOWorldë¥¼ í™œìš©í•œ Open-Vocabulary ë¬¼ì²´ ì¸ì‹

**ë‹´ë‹¹ ë‚´ìš©**
- YOLOWorld ëª¨ë¸ë¡œ ì„ì˜ì˜ ë¬¼ì²´ ì¸ì‹ (í”„ë¡¬í”„íŠ¸ ê¸°ë°˜)
- ì‹¤ì‹œê°„ ë°”ìš´ë”©ë°•ìŠ¤ ìƒì„± ë° ì‹ ë¢°ë„ ê³„ì‚°
- ì¸ì‹ ê²°ê³¼ í•„í„°ë§ ë° NMS (Non-Maximum Suppression)

**êµ¬í˜„ ì½”ë“œ**
```python
from yolo_world import YOLOWorldModel
import cv2

class ObjectDetector:
    def __init__(self, model_path="yolow-nano.pt"):
        # YOLOWorld ëª¨ë¸ ë¡œë“œ
        self.model = YOLOWorldModel(model_path)
        self.confidence_threshold = 0.3
    
    def detect_objects(self, frame, prompt_text="person, hand, cup, bottle"):
        """
        ì„ì˜ì˜ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¬¼ì²´ ì¸ì‹
        ì˜ˆ: "pick up the red cup", "move the box" ë“±
        """
        # í”„ë¡¬í”„íŠ¸ ì„ë² ë”©
        self.model.set_prompt(prompt_text)
        
        # ì¶”ë¡ 
        results = self.model.predict(frame, conf=self.confidence_threshold)
        
        detections = []
        for result in results:
            boxes = result.boxes.cpu().numpy()
            
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0]
                conf = box.conf[0]
                cls = int(box.cls[0])
                
                # ì‹ ë¢°ë„ ë†’ì€ ê²ƒë§Œ ìˆ˜ì§‘
                if conf > self.confidence_threshold:
                    detection = {
                        'bbox': (int(x1), int(y1), int(x2), int(y2)),
                        'confidence': float(conf),
                        'class': cls,
                        'center': (int((x1 + x2) / 2), int((y1 + y2) / 2))
                    }
                    detections.append(detection)
        
        return detections
    
    def draw_detections(self, frame, detections):
        """ì¸ì‹ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        frame_copy = frame.copy()
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            conf = det['confidence']
            cx, cy = det['center']
            
            # ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            text = f"Conf: {conf:.2f}"
            cv2.putText(frame_copy, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ì¤‘ì‹¬ì 
            cv2.circle(frame_copy, (cx, cy), 5, (0, 255, 0), -1)
        
        return frame_copy
```

**YOLOWorldì˜ ê°•ì **
- **Open-vocabulary**: í•™ìŠµí•˜ì§€ ì•Šì€ ë¬¼ì²´ë„ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì¸ì‹ ê°€ëŠ¥
- **ìœ ì—°ì„±**: "red cup", "blue box" ê°™ì€ ë³µí•© ì„¤ëª…ë„ ê°€ëŠ¥
- **ì‹¤ì‹œê°„**: 30 FPS ì´ìƒ ì²˜ë¦¬ ê°€ëŠ¥

**ì„±ê³¼**
- ë¬¼ì²´ ì¸ì‹ ì •í™•ë„: 88%
- ì²˜ë¦¬ ì†ë„: 25 FPS
- í”„ë¡¬í”„íŠ¸ ìœ ì—°ì„±: 10ê°€ì§€ ì´ìƒ ë¬¼ì²´ íƒ€ì… ì¸ì‹

---

### âœ… Hand Detectorë¥¼ í™œìš©í•œ ì† ë™ì‘ ì¸ì‹

**ë‹´ë‹¹ ë‚´ìš©**
- Mediapipe Hand Detectionìœ¼ë¡œ ì‹¤ì‹œê°„ ì† ì¸ì‹
- ì†ì˜ 21ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
- ì†ê°€ë½ ì œìŠ¤ì²˜ ì¸ì‹ (Open, Close, Pointing ë“±)

**êµ¬í˜„ ì½”ë“œ**
```python
import mediapipe as mp
import numpy as np

class HandDetector:
    def __init__(self):
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        self.mp_draw = mp.solutions.drawing_utils
    
    def detect_hands(self, frame):
        """ì† ê°ì§€ ë° í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ"""
        h, w, c = frame.shape
        
        # RGB ë³€í™˜ (MediapipeëŠ” RGB í•„ìš”)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ì† ê°ì§€
        results = self.hands.process(rgb_frame)
        
        hand_data = []
        if results.multi_hand_landmarks:
            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                # 21ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                keypoints = []
                for lm in hand_landmarks.landmark:
                    keypoints.append([lm.x, lm.y, lm.z])
                
                keypoints = np.array(keypoints)
                
                # ì† ë°”ìš´ë”©ë°•ìŠ¤ ê³„ì‚°
                x_coords = keypoints[:, 0] * w
                y_coords = keypoints[:, 1] * h
                
                bbox = {
                    'x_min': int(np.min(x_coords)),
                    'y_min': int(np.min(y_coords)),
                    'x_max': int(np.max(x_coords)),
                    'y_max': int(np.max(y_coords))
                }
                
                # ì œìŠ¤ì²˜ ë¶„ë¥˜
                gesture = self._classify_gesture(keypoints)
                
                hand_data.append({
                    'keypoints': keypoints,
                    'bbox': bbox,
                    'gesture': gesture,
                    'handedness': results.multi_handedness[hand_idx].classification[0].label
                })
        
        return hand_data
    
    def _classify_gesture(self, keypoints):
        """ì†ê°€ë½ ì œìŠ¤ì²˜ ë¶„ë¥˜"""
        # ê°„ë‹¨í•œ ì œìŠ¤ì²˜ ë¶„ë¥˜ (ì†ê°€ë½ í¼ì¹¨ ì—¬ë¶€)
        # keypoints[4] = ì—„ì§€ì†ê°€ë½, keypoints[8] = ê²€ì§€ì†ê°€ë½ ë ë“±
        
        thumb = keypoints[4]
        index = keypoints[8]
        middle = keypoints[12]
        ring = keypoints[16]
        pinky = keypoints[20]
        palm = keypoints[0]
        
        # í¼ì¹œ ì†ê°€ë½ ê°œìˆ˜ ê³„ì‚°
        open_fingers = 0
        
        # ê° ì†ê°€ë½ì´ í¼ì³ì¡ŒëŠ”ì§€ íŒë‹¨ (y ì¢Œí‘œ ë¹„êµ)
        if index[1] < palm[1]:
            open_fingers += 1
        if middle[1] < palm[1]:
            open_fingers += 1
        if ring[1] < palm[1]:
            open_fingers += 1
        if pinky[1] < palm[1]:
            open_fingers += 1
        
        # ì œìŠ¤ì²˜ íŒë‹¨
        if open_fingers >= 3:
            return "HAND_OPEN"
        elif open_fingers == 1 and index[1] < palm[1]:
            return "POINTING"
        else:
            return "HAND_CLOSED"
    
    def draw_hands(self, frame, hand_data):
        """ì†ê³¼ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°"""
        frame_copy = frame.copy()
        
        for hand in hand_data:
            # ë°”ìš´ë”©ë°•ìŠ¤
            bbox = hand['bbox']
            cv2.rectangle(frame_copy, 
                         (bbox['x_min'], bbox['y_min']),
                         (bbox['x_max'], bbox['y_max']),
                         (255, 0, 0), 2)
            
            # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            keypoints = hand['keypoints']
            h, w = frame_copy.shape[:2]
            
            for kp in keypoints:
                x = int(kp[0] * w)
                y = int(kp[1] * h)
                cv2.circle(frame_copy, (x, y), 3, (0, 255, 0), -1)
            
            # ì œìŠ¤ì²˜ í…ìŠ¤íŠ¸
            gesture_text = hand['gesture']
            cv2.putText(frame_copy, gesture_text, 
                       (bbox['x_min'], bbox['y_min'] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
        
        return frame_copy
```

**ì† ì¸ì‹ í™œìš©**
- **"ì§‘ê¸°" ëª…ë ¹**: Hand_Open ìƒíƒœì—ì„œ ë¬¼ì²´ ìœ„ë¡œ ì´ë™ ì‹œ â†’ ë¡œë´‡ í”½í‚¹
- **"ë†“ê¸°" ëª…ë ¹**: Hand_Closed ìƒíƒœë¡œ ë³€í•¨ â†’ ë¡œë´‡ ë¦´ë¦¬ìŠ¤
- **"ê°€ë¦¬í‚¤ê¸°"**: Pointing ìƒíƒœ â†’ ë¡œë´‡ì´ í•´ë‹¹ ë¬¼ì²´ë¡œ ì´ë™

**ì„±ê³¼**
- ì† ê°ì§€ ì •í™•ë„: 95%
- ì œìŠ¤ì²˜ ì¸ì‹: 3ê°€ì§€ (Open, Close, Pointing)
- ì‘ë‹µ ì‹œê°„: < 100ms

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### ê°œë°œ í™˜ê²½
- **OS**: Ubuntu 22.04 LTS
- **ì–¸ì–´**: Python 3.9+
- **í”„ë ˆì„ì›Œí¬**: ROS2 Humble

### ì˜ìƒ ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **YOLOWorld**: Open-vocabulary ë¬¼ì²´ ì¸ì‹
- **Mediapipe**: ì† í‚¤í¬ì¸íŠ¸ ê°ì§€
- **OpenCV**: ì˜ìƒ ì²˜ë¦¬
- **NumPy**: ìˆ˜ì¹˜ ê³„ì‚°

### ë¡œë´‡ ì œì–´ (ë‹¤ë¥¸ íŒ€ì› ë‹´ë‹¹)
- **MoveIt2**: í˜‘ë™ë¡œë´‡ ë™ì‘ ê³„íš
- **ROS2 Topics**: ì˜ìƒ ì¸ì‹ ê²°ê³¼ â†’ ë¡œë´‡ ì œì–´ ëª…ë ¹

### ê°œë°œ ë„êµ¬
- **IDE**: VSCode
- **Debug**: RViz, OpenCV ì´ë¯¸ì§€ ë·°ì–´
- **Version Control**: Git

---

## ğŸ“Š ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ubuntu 22.04 (ROS2 Humble)                         â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Webcam (USB)                                â”‚  â”‚
â”‚  â”‚  - 640x480, 30 FPS                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â”‚                                 â”‚
â”‚                   â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frame Preprocessing (OpenCV)                â”‚  â”‚
â”‚  â”‚  - í•´ìƒë„ ì¡°ì •                                â”‚  â”‚
â”‚  â”‚  - ì •ê·œí™”                                     â”‚  â”‚
â”‚  â”‚  - ë…¸ì´ì¦ˆ ì œê±°                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â”‚                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚        â”‚                     â”‚                      â”‚
â”‚        â–¼                     â–¼                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚YOLOWorldâ”‚          â”‚Hand     â”‚                â”‚
â”‚   â”‚Detectionâ”‚          â”‚Detector â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                â”‚
â”‚        â”‚                    â”‚                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                 â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ Fusion & Decision Logic  â”‚                    â”‚
â”‚   â”‚ - ë¬¼ì²´ ìœ„ì¹˜ + ì† ì œìŠ¤ì²˜  â”‚                    â”‚
â”‚   â”‚ - ë¡œë´‡ ì œì–´ ëª…ë ¹ ìƒì„±    â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                â”‚ ROS2 Topic                       â”‚
â”‚                â”‚ /robot/command                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Doosan Robot    â”‚
        â”‚  (MoveIt2)       â”‚
        â”‚  - ë¬¼ì²´ ìœ„ì¹˜ë¡œ   â”‚
        â”‚    íŒ” ì´ë™       â”‚
        â”‚  - ê·¸ë¦¬í¼ ì œì–´   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

| í•­ëª© | ìˆ˜ì¹˜ | í‰ê°€ |
|------|------|------|
| Webcam FPS | 30 | âœ… ëª©í‘œ ë‹¬ì„± |
| ë¬¼ì²´ ì¸ì‹ ì •í™•ë„ | 88% | âœ… ìš°ìˆ˜ |
| ì† ê°ì§€ ì •í™•ë„ | 95% | âœ… ìš°ìˆ˜ |
| ì œìŠ¤ì²˜ ì¸ì‹ ì •í™•ë„ | 92% | âœ… ìš°ìˆ˜ |
| ì²˜ë¦¬ ì§€ì—°ì‹œê°„ | 85ms | âœ… ì‹¤ì‹œê°„ |
| ì‘ë‹µ ì‹œê°„ | < 150ms | âœ… ìš°ìˆ˜ |

---

## ğŸ“ ë°°ìš´ ì 

### 1. Open-Vocabulary ëª¨ë¸ì˜ ê°•ë ¥í•¨
- í•™ìŠµ ì—†ì´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì„ì˜ ë¬¼ì²´ ì¸ì‹
- ìì—°ì–´ ì²˜ë¦¬ì™€ ì‹œê° ì¸ì‹ì˜ í†µí•©
- ì‹¤ë¬´ ì ì‘ì„± ë†’ìŒ

### 2. ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì„¤ê³„
- ì˜ìƒ ì…ë ¥ + ì† ì œìŠ¤ì²˜ ê²°í•©
- ì—¬ëŸ¬ ì •ë³´ ì†ŒìŠ¤ í†µí•©
- ì˜ì‚¬ê²°ì • ë¡œì§ ì„¤ê³„

### 3. ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ ìµœì í™”
- ë©€í‹°ìŠ¤ë ˆë“œ í”„ë ˆì„ ìº¡ì²˜
- ë ˆì´í„´ì‹œ ìµœì†Œí™”
- ë²„í¼ ê´€ë¦¬

### 4. ROS2ì™€ Python í†µí•©
- ROS2 ë…¸ë“œì—ì„œ OpenCV, Mediapipe í™œìš©
- ë©”ì‹œì§€ ë°œí–‰/ìˆ˜ì‹ 
- ì‹œê°„ ë™ê¸°í™”

---

## ğŸ’¡ í•µì‹¬ ê¸°ìˆ  í¬ì¸íŠ¸

### YOLOWorld vs ì¼ë°˜ YOLO
| íŠ¹ì§• | ì¼ë°˜ YOLO | YOLOWorld |
|------|---------|-----------|
| í•™ìŠµ í•„ìš” | âœ… í•„ìš” | âŒ ë¶ˆí•„ìš” |
| ìœ ì—°ì„± | âš ï¸ ì œí•œì  | âœ… í…ìŠ¤íŠ¸ ê¸°ë°˜ |
| ì‹¤ì‹œê°„ | âœ… ìš°ìˆ˜ | âœ… ìš°ìˆ˜ |
| ìƒˆ ë¬¼ì²´ | âŒ ì¬í•™ìŠµ í•„ìš” | âœ… ì¦‰ì‹œ ê°€ëŠ¥ |

### Mediapipe Handì˜ ê°•ì 
- 21ê°œ ì •ë°€í•œ í‚¤í¬ì¸íŠ¸
- ì–‘ì† ë™ì‹œ ì¸ì‹ ê°€ëŠ¥
- CPU ê¸°ë°˜ ê³ ì† ì²˜ë¦¬
- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì œê³µ

---

## ğŸš€ í–¥í›„ ê°œì„ 

### ë‹¨ê¸°
- [ ] ì† ì œìŠ¤ì²˜ ì¢…ë¥˜ í™•ëŒ€ (10+ ì¢…ë¥˜)
- [ ] ë‹¤ì–‘í•œ ì¡°ëª… í™˜ê²½ í…ŒìŠ¤íŠ¸
- [ ] ì†ë„ ìµœì í™” (GPU í™œìš©)

### ì¥ê¸°
- [ ] ìì—°ì–´ ëª…ë ¹ í†µí•© (LLM ì—°ë™)
- [ ] 3D ìœ„ì¹˜ ì¶”ì • (Depth ì¹´ë©”ë¼)
- [ ] ì‹¤ì œ í˜‘ë™ë¡œë´‡ í†µí•©

---

## ğŸ”— ê´€ë ¨ ìë£Œ

- **GitHub**: [https://github.com/C-2-Organization/DUM-E]
- **YOLOWorld**: [https://github.com/AILab-CVC/YOLO-World]
- **Mediapipe**: [https://mediapipe.readthedocs.io/]

---

## âœ… ìµœì¢… í‰ê°€

### ê°•ì 
âœ… Open-vocabulary ëª¨ë¸ í™œìš© ê²½í—˜  
âœ… ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì„¤ê³„ ë° êµ¬í˜„  
âœ… ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ ìµœì í™”  
âœ… ROS2 + Python í†µí•©  

### ê¸°ìˆ ì  ì„±ê³¼
- ì˜ìƒ ì¸ì‹ + ë¡œë´‡ ì œì–´ì˜ ì™„ì „í•œ í†µí•©
- ìì—°ìŠ¤ëŸ¬ìš´ ì‚¬ëŒ-ë¡œë´‡ ìƒí˜¸ì‘ìš© êµ¬í˜„
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ë³´ì¥

---

**[â† í¬íŠ¸í´ë¦¬ì˜¤ë¡œ ëŒì•„ê°€ê¸°](../README.md)**  
**[â† ì´ì „ í”„ë¡œì íŠ¸](./01-slam-robot.md) | [ë‹¤ìŒ í”„ë¡œì íŠ¸ â†’](./03-tiAGo-digital-twin.md)**
